{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.collection_agent import CollectionAgent\n",
    "import os\n",
    "from glob import glob\n",
    "import gradio as gr\n",
    "import pandas as pd\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!pip install pymupdf4llm -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "files = glob(\"/Users/admin/Projects/MathTestCreator/Documents/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf\n",
    "from agents.source_material import SourceMaterial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/anaconda3/envs/testg/lib/python3.11/site-packages/langchain_community/document_loaders/parsers/pdf.py:322: UserWarning: Warning: Empty content on page 1 of document /Users/admin/Projects/MathTestCreator/Documents/further.pdf\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "material = SourceMaterial(files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/admin/Projects/MathTestCreator/Documents/further.pdf'"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(material.load_markdown(files[0]))\n",
    "material.metadata['total_pages']\n",
    "material.source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "434\n"
     ]
    }
   ],
   "source": [
    "print(len(material.documents.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.collection_agent import CollectionAgent\n",
    "collectionAgent = CollectionAgent()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaaaaaaaa\n",
      "/Users/admin/Projects/MathTestCreator/Documents/further.pdf\n",
      "already uploaded\n"
     ]
    }
   ],
   "source": [
    "collectionAgent.create_source_material(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[further.pdf - The document, \"Advanced High-School Mathematics\" by David B. Surowski, outlines his experiences in developing advanced mathematics notes for students seeking further studies beyond the standard curriculum. It covers various topics including geometry, discrete mathematics, and inferential statistics while emphasizing the importance of logical reasoning in mathematics education.]"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collectionAgent.documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"You are a helpful assist. Be polite and courteous. Guide the user through the process of creating a math test.\\\n",
    "                    The user is provided with parameters to set in the interface. Prompt them to use the interface to set the parameters.\\\n",
    "                If they do not want to use parameters you can ask them for more information or make a decision on their behalf.\\\n",
    "                    \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7948\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7948/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collectionAgent = CollectionAgent()\n",
    "def do_entry(message, history):\n",
    "        history += [{\"role\":\"user\", \"content\":message}]\n",
    "        return \"\", history\n",
    "\n",
    "def docdata_to_text():\n",
    "        for i, material in enumerate(collectionAgent.documents):\n",
    "            yield f\"### Document {i+1}: \\n\\n {repr(material)}\"\n",
    "\n",
    "def chat_gpt(history, parameters={}):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history\n",
    "    if parameters.values():\n",
    "        messages.append({\"role\":\"assistant\", \"content\":parameters})\n",
    "    else:\n",
    "        messages.append({\"role\":\"assistant\", \"content\":\"Do you have any specifications?\"})\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    reply = response.choices[0].message.content\n",
    "    history += [{\"role\":\"assistant\", \"content\":reply}]\n",
    "    return history\n",
    "\n",
    "with gr.Blocks() as ui:\n",
    "\n",
    "    documents = gr.State()\n",
    "    collection = gr.State()\n",
    "\n",
    "    gr.Markdown(\"##Math Test Creator\")\n",
    "    gr.Markdown(\"#### Upload files to use as source material for your test\")\n",
    "    with gr.Row():\n",
    "            with gr.Column():\n",
    "                file_uploader = gr.File(file_count=\"multiple\")\n",
    "            with gr.Column():\n",
    "                gr.Markdown(\"### Here are the documents you have uploaded\")\n",
    "                doc_data = gr.Markdown(label=\"Document Data\")\n",
    "    with gr.Row():\n",
    "        rag_button = gr.Button(\"Create Your Custom Assistant\")\n",
    "        output = gr.Markdown(label=\"Response:\")\n",
    "    with gr.Row():\n",
    "        chatbot = gr.Chatbot(type='messages')\n",
    "    \n",
    "    with gr.Row():\n",
    "        chat_entry = gr.Textbox()\n",
    "    #Set Parameters\n",
    "    file_uploader.change(collectionAgent.create_source_material, inputs=[file_uploader], outputs=[documents]).then(docdata_to_text, inputs=[], outputs=[doc_data])\n",
    "\n",
    "    # file_uploader.change(ragAgent.load_files, inputs=[file_uploader], outputs=[documents]).then(ragAgent.document_data, inputs=[], outputs=[doc_data]).then(ragAgent.setup, inputs=[], outputs=[collection])\n",
    "    \n",
    "    chat_entry.submit(do_entry, inputs=[chat_entry, chatbot], outputs=[chat_entry, chatbot]).then(\n",
    "        chat_gpt, inputs=chatbot, outputs=chatbot)\n",
    "    \n",
    "\n",
    "\n",
    "ui.launch()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7876\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7876/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collectionAgent = CollectionAgent()\n",
    "def do_entry(message, history):\n",
    "        history += [{\"role\":\"user\", \"content\":message}]\n",
    "        return \"\", history\n",
    "\n",
    "def docdata_to_text():\n",
    "        for material in collectionAgent.documents:\n",
    "            yield f\"### Document Successfully Uploaded\\n\\n {repr(material)}\"\n",
    "def doc_to_df():\n",
    "     return pd.DataFrame([[doc.name, str(doc.length) + ' ' + doc.length_type] for doc in collectionAgent.documents],columns = [\"Name\", \"Length\"])\n",
    "def set_visibility():\n",
    "    if customize == \"Do you want make custom selections of your material?\":\n",
    "         return gr.update(visible=True)\n",
    "    \n",
    "    doc_df_visibility = False if len(collectionAgent.documents) == 0 else True\n",
    "    return gr.update(visible=doc_df_visibility)\n",
    "     \n",
    "def chat_gpt(history, parameters={}):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history\n",
    "    if parameters.values():\n",
    "        messages.append({\"role\":\"assistant\", \"content\":parameters})\n",
    "    else:\n",
    "        messages.append({\"role\":\"assistant\", \"content\":\"Do you have any specifications?\"})\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    reply = response.choices[0].message.content\n",
    "    history += [{\"role\":\"assistant\", \"content\":reply}]\n",
    "    return history\n",
    "\n",
    "with gr.Blocks() as ui:\n",
    "    with gr.Row():\n",
    "        chatbot = gr.Chatbot(type='messages')\n",
    "    \n",
    "    with gr.Row():\n",
    "        chat_entry = gr.Textbox()\n",
    "    #Set Parameters\n",
    "\n",
    "\n",
    "    documents = gr.State()\n",
    "    collection = gr.State()\n",
    "    gr.Markdown(\"## Custom Personal Knowledge Assistant\")\n",
    "    interim =  gr.Markdown(\"#### Upload a File\")\n",
    "    with gr.Row():\n",
    "            with gr.Column():\n",
    "                file_uploader = gr.File(file_count=\"multiple\")\n",
    "            with gr.Column():\n",
    "                # gr.Markdown(\"### Here are the documents you have uploaded\")\n",
    "                doc_data = gr.Markdown(label=\"Document Data\")\n",
    "    with gr.Row():\n",
    "         doc_df = gr.DataFrame(headers = [\"No documents uploaded\"]\n",
    "         )\n",
    "    with gr.Row():\n",
    "         customize = gr.Checkbox([\"Do you want make custom selections of your material?\"],label=\"Document Selection\", )  \n",
    "    with gr.Row():\n",
    "         pages = gr.slider(label=\"Choose your starting page\")\n",
    "    with gr.Row():\n",
    "        rag_button = gr.Button(\"Create Your Custom Assistant\")\n",
    "        output = gr.Markdown(label=\"Response:\")\n",
    "    \n",
    "    file_uploader.change(collectionAgent.create_source_material, inputs=[file_uploader], outputs=[documents]).then(docdata_to_text, inputs=[], outputs=[doc_data]).then(doc_to_df, outputs=doc_df)\n",
    "\n",
    "    # file_uploader.change(ragAgent.load_files, inputs=[file_uploader], outputs=[documents]).then(ragAgent.document_data, inputs=[], outputs=[doc_data]).then(ragAgent.setup, inputs=[], outputs=[collection])\n",
    "    customize.change(show_parameters, inputs=customize, outputs=pages)\n",
    "\n",
    "    chat_entry.submit(do_entry, inputs=[chat_entry, chatbot], outputs=[chat_entry, chatbot]).then(\n",
    "        chat_gpt, inputs=chatbot, outputs=chatbot)\n",
    "    \n",
    "\n",
    "\n",
    "ui.launch()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ui.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import pandas as pd\n",
    "\n",
    "# Initial parameters for the editable table (as a list of lists)\n",
    "initial_data = [\n",
    "    [\"Learning Rate\", 0.001],\n",
    "    [\"Batch Size\", 32],\n",
    "    [\"Epochs\", 10],\n",
    "]\n",
    "\n",
    "# Function to process and display updated parameters\n",
    "def update_parameters(dataframe):\n",
    "    # Convert the editable dataframe into a Pandas DataFrame\n",
    "    df = pd.DataFrame(dataframe, columns=[\"Parameter\", \"Value\"])\n",
    "    # Process or validate the data if needed\n",
    "    return f\"Updated Parameters:\\n{df.to_string(index=False)}\"\n",
    "\n",
    "# Gradio Interface\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## Editable Table of Parameters\")\n",
    "    \n",
    "    # Editable dataframe\n",
    "    parameter_table = gr.Dataframe(\n",
    "        value=initial_data,\n",
    "        headers=[\"Parameter\", \"Value\"],\n",
    "        datatype=[\"str\", \"number\"],  # Specify data types for columns\n",
    "        row_count=(3, \"dynamic\"),  # Allow dynamic row addition\n",
    "        col_count=(2, \"fixed\"),  # Fixed number of columns\n",
    "        interactive=True,  # Make the table editable\n",
    "        label=\"Edit Parameters\"\n",
    "    )\n",
    "    \n",
    "    # Output area to display the processed parameters\n",
    "    output = gr.Textbox(label=\"Output\", interactive=False, lines=5)\n",
    "    \n",
    "    # Button to submit changes\n",
    "    update_button = gr.Button(\"Update Parameters\")\n",
    "    \n",
    "    # Update button triggers the update process\n",
    "    update_button.click(update_parameters, inputs=[parameter_table], outputs=[output])\n",
    "\n",
    "# Launch the Gradio app\n",
    "demo.launch(server_port=7860)\n",
    "demo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
